{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6904f85-d199-4e44-bce3-60ff1475f82b",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook contains tobit modeling code for linear regression. The goal is to take a look at which factors contribute to the chosen score (deprawsc) the most. Features with too many NaNs are filtered out, since the model selected cannot handle NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c44b9b-44b6-4779-9a03-ceb0e23c9a60",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674638b-83dd-445d-a8f6-a8b635486a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from tobit_model4 import TobitModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d31fc8-1ee9-45b7-9e3c-693bd9d3a462",
   "metadata": {},
   "source": [
    "and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85ca41-ae18-4c0b-9cec-9764e5c76899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld = pd.read_csv(\"../data/processed/all_data_train.csv\")\n",
    "df_total = pd.read_csv(\"../data/processed/all_data_additional_train.csv\")\n",
    "df_val = pd.read_csv(\"../data/processed/all_data_validation.csv\")\n",
    "df = pd.concat([dfOld,df_total])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72619102-0887-4c24-a049-def65822c5b5",
   "metadata": {},
   "source": [
    "creating a constant columns necessary for tobit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7878a6-c2a1-417f-8d97-83600c1c9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['constant'] = np.ones(len(df))\n",
    "df_val['constant'] = np.ones(len(df_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9727e6-6bb6-4cb9-b223-b423393c4225",
   "metadata": {},
   "source": [
    "## Max education of parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35926af-6994-424a-8adf-72c4d41bcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['educ_par_max'] = df[['educ_par1', 'educ_par2']].max(axis=1)\n",
    "df_val['educ_par_max'] = df_val[['educ_par1', 'educ_par2']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff531129-b93d-44b7-976c-8a89a427ff20",
   "metadata": {},
   "source": [
    "## Filtering columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766ec6a-ae01-40dd-971b-144ea14e9aa3",
   "metadata": {},
   "source": [
    "and filter out those that have too many NaNs (more than 10 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db3ac8-ab19-449b-b0b6-9d986e1ca67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresPre=['constant','deprawsc', 'fincur','age','gender','race', 'educ_par_max', 'residenc', 'international', 'degree', 'gpa_sr', 'alc_any', 'exerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427bffc-67fd-4093-b1dd-1d2d85847496",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "mask = ~np.isnan(df['deprawsc'])\n",
    "maskval = ~np.isnan(df_val['deprawsc'])\n",
    "maskp = int(sum(np.isnan(df['deprawsc']))/len(df)*100)\n",
    "print(f'deprawsc has {maskp}% NaNs')\n",
    "for feature in featuresPre:\n",
    "    #print(feature)\n",
    "    if (feature == 'deprawsc') | (feature == 'degree') | (feature == 'field'):\n",
    "        continue\n",
    "    markpf = int(sum(np.isnan(df[feature]))/len(df)*100)\n",
    "    if (markpf > 10) & (feature != 'exerc'): \n",
    "        print('Feature ' + str(feature) + f' has too many NaNs: {markpf}%. Removing.')\n",
    "    else:\n",
    "        print('Feature ' + str(feature) + f' has {markpf}% NaNs. Keeping.')\n",
    "        mask &= ~np.isnan(df[feature])\n",
    "        maskval &= ~np.isnan(df_val[feature])\n",
    "        features.append(feature)\n",
    "markTotal = int(len(df[~mask])/len(df)*100)\n",
    "print(f'Total {markTotal}% to be removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e47a3c-f8a9-45c7-bc3d-65f26c454df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8373fb-f793-4004-bd24-93981556ce33",
   "metadata": {},
   "source": [
    "## Intersectionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23a30a-1f17-4de3-956f-92ee6872cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersectionality_columns={}\n",
    "intersectionality_columns_val={}\n",
    "intersectionality_features=[]\n",
    "#features_narrow=['gender', 'age', 'fincur', 'race', 'alc_any']\n",
    "features_narrow=[ 'age', 'fincur', 'alc_any']\n",
    "for feature1 in features_narrow:\n",
    "    for feature2 in features_narrow:\n",
    "        if feature1 == feature2:\n",
    "            continue\n",
    "        newfeature = feature1 + '_and_' + feature2\n",
    "        oldfeature = feature2 + '_and_' + feature1\n",
    "        if (not newfeature in intersectionality_features) and (not oldfeature in intersectionality_features):\n",
    "            intersectionality_columns[newfeature] = df[feature1]*df[feature2]\n",
    "            intersectionality_columns_val[newfeature] = df_val[feature1]*df_val[feature2]\n",
    "            intersectionality_features.append(newfeature)\n",
    "new_cols_df = pd.DataFrame(intersectionality_columns)\n",
    "new_cols_df_val = pd.DataFrame(intersectionality_columns_val)\n",
    "df = pd.concat([df, new_cols_df], axis=1)\n",
    "df_val = pd.concat([df_val, new_cols_df_val], axis=1)\n",
    "features += intersectionality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b19ad-4d68-4d71-a3e2-748bc995b6e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intersectionality_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d81fa-e81a-4584-8fac-efff66649747",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787a142-8443-4e9f-bf1f-a815066febe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de66e6-5abb-4360-824b-637c8d22c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df[mask],shuffle=True,random_state=440,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675b7ae-8a46-4a72-b406-0a5e2a5796f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfiltered=df_train[features]\n",
    "Yfiltered=df_train['deprawsc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160377b-81d9-4ee1-a73f-0e3d61c8f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=df_test[features]\n",
    "Ytest=df_test['deprawsc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0245c-9f7f-4c55-8b46-5f1da7dfda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval=df_val[maskval][features]\n",
    "Yval=df_val[maskval]['deprawsc'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a02fa-d268-4d08-beca-00d07a9e6ff2",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0b027-158d-4aa4-ab49-28663eeaa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=['educ_par_max','gender','race','international','residenc','alc_any']\n",
    "numerical_features=['gpa_sr','fincur','age','exerc'] + intersectionality_features\n",
    "const_features=['constant']\n",
    "numerical_transformer=StandardScaler()\n",
    "const_transformer='passthrough'\n",
    "categorical_transformer=OneHotEncoder(handle_unknown='ignore', drop=[1,2,7,0,1,0])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('con', const_transformer, const_features),\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea84906-cb44-4605-9821-9b68156d9935",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be95df0-4e16-443c-9faa-a639e7be3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', TobitModel(ul=27,lol=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6ab75-4a35-4524-bf51-3b58257befbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(Xfiltered, Yfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c78a95-99c4-47a2-b469-8b77e8291230",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "coefficients = pd.Series(pipeline.named_steps['model'].params_[:-1], index=feature_names)\n",
    "pvalues = pd.Series(np.round(pipeline.named_steps['model'].p_values[:-1],3), index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503d3da-b137-423f-b3f2-1f3f342d0926",
   "metadata": {},
   "source": [
    "## Looking at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad6f7a-e3ed-42c5-bbb5-fe8f264e4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_dict={feature: coefficients[feature] for feature in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c505b-8c99-4111-9a28-b87f7e3f77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_impact = sorted(impact_dict.items(), key=lambda item: np.abs(item[1]),reverse=True)\n",
    "sorted_impact_asc = list(dict(sorted_impact))#[:20]\n",
    "print('Top features: ')\n",
    "for feature in sorted_impact_asc:\n",
    "    print(str(feature) + ' has impact ' + str(dict(sorted_impact)[feature]) + ' w/ p value ' + str(pvalues[feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede13ad-0e2d-4c05-a9dc-b8fb55df2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those with low p value\n",
    "sorted_impact_all = list(dict(sorted_impact))\n",
    "significant_features=[]\n",
    "for feature in sorted_impact_all:\n",
    "    if pvalues[feature] < 0.05:\n",
    "        significant_features.append(feature)\n",
    "print('Top (significant) features: ')\n",
    "for feature in significant_features:\n",
    "    print(str(feature) + ' has impact ' + str(dict(sorted_impact)[feature]) + ' w/ p value ' + str(pvalues[feature]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d5cb3-4c1d-4fcd-969f-43dfedd59996",
   "metadata": {},
   "source": [
    "## Confusion matrix etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323cf8b-99be-4adb-892f-20521b28fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.median(Ytest)\n",
    "print(threshold)\n",
    "thresholdVal = np.median(Yval)\n",
    "print(thresholdVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc0447-129f-4adf-9b5d-351a43296a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(Xtest)\n",
    "preds[preds > 27] = 27\n",
    "preds[preds < 0] = 0\n",
    "\n",
    "\n",
    "preds_happy = (preds < threshold).astype(int)\n",
    "y_val_happy = (Ytest < threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_val_happy, preds_happy)\n",
    "\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "TP = cm[1, 1]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Define display labels if desired\n",
    "display_labels = ['unhappy', 'happy']\n",
    "\n",
    "# Create a display object\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "\n",
    "# Plot the matrix\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print('accuracy = ', str(accuracy*100))\n",
    "print('precision = ', str(precision*100))\n",
    "print('recall = ', str(recall*100))\n",
    "print('f1 = ', str(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7974fd-9613-4363-a993-fd1f8fb427b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsval = pipeline.predict(Xval)\n",
    "predsval[predsval > 27] = 27\n",
    "predsval[predsval < 0] = 0\n",
    "tobis_predict=pipeline.predict(Xval)\n",
    "tobis_mse=mse(Yval,tobis_predict)\n",
    "\n",
    "\n",
    "valpreds_happy = (predsval < thresholdVal).astype(int)\n",
    "valy_val_happy = (Yval < thresholdVal).astype(int)\n",
    "\n",
    "cm = confusion_matrix(valy_val_happy, valpreds_happy)\n",
    "\n",
    "TNV = cm[0, 0]\n",
    "FPV = cm[0, 1]\n",
    "FNV = cm[1, 0]\n",
    "TPV = cm[1, 1]\n",
    "\n",
    "accuracyV = (TPV + TNV) / (TPV + TNV + FPV + FNV)\n",
    "precisionV = TPV / (TPV + FPV)\n",
    "recallV = TPV / (TPV + FNV)\n",
    "f1V = 2 * (precisionV * recallV) / (precisionV + recallV)\n",
    "\n",
    "# Define display labels if desired\n",
    "display_labels = ['unhappy', 'happy']\n",
    "\n",
    "# Create a display object\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "\n",
    "# Plot the matrix\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print('accuracy = ', str(accuracyV*100))\n",
    "print('precision = ', str(precisionV*100))\n",
    "print('recall = ', str(recallV*100))\n",
    "print('f1 = ', str(f1V*100))\n",
    "print(f'MSE = {tobis_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
