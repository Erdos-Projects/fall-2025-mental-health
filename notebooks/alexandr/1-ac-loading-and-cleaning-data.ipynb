{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcc394c-8ec2-4df7-aadc-e90ddfcda886",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook contains data cleaning routines for loading academic data: year of study (yr_sch), enrollment status (enroll), GPA (gpa_sr or gr_{A,B,C,D,F,none,dk}), degree type (degree_\\*), field type (field_\\*)impact of mental health on studies (aca_impa), ability to persist in the studies (persist). Null values and irregular situations (more than 2 degrees at once, more than 3 fields at once) are flagged for removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb8898-adbb-4b93-87b2-4393a8e85f52",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08024dd9-966e-4411-9509-5cf8959f9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35055f7f-8cdc-408e-ad08-6b58e4ee75d2",
   "metadata": {},
   "source": [
    "## Load the file \n",
    "\n",
    "\n",
    "### Release notes:\n",
    "\n",
    "Note that 2020-2021 is very different since textual answers were used instead of numerical ones. Afterwards, gr_{A,B,C,D,F,dk,none} were used instead of gpa_sr. Some years have gr_{a,b,c,d,d,f,dk,none} instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f7ad9-ac16-4d47-9e75-d9b4e7590072",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2024\n",
    "field_cols=[\"field_hum\",\"field_nat\",\"field_soc\",\"field_arc\",\"field_art\",\"field_bus\",\"field_den\",\"field_ed\",\"field_eng\",\"field_law\",\"field_med\",\"field_mus\",\"field_nur\",\"field_pharm\",\"field_prep\",\"field_ph\",\"field_pp\",\"field_sw\",\"field_und\",\"field_other\"]\n",
    "degree_cols=[\"degree_ass\",\"degree_bach\",\"degree_ma\",\"degree_jd\",\"degree_phd\",\"degree_other\",\"degree_nd\"]\n",
    "if year==2021 or year==2022:\n",
    "    gpa_cols=[\"gr_a\",\"gr_b\",\"gr_c\",\"gr_d\",\"gr_f\",\"gr_none\",\"gr_dk\"]\n",
    "elif year==2020 or year > 2022:\n",
    "    gpa_cols=[\"gr_A\",\"gr_B\",\"gr_C\",\"gr_D\",\"gr_F\",\"gr_none\",\"gr_dk\"]\n",
    "else:\n",
    "    gpa_cols=[\"gpa_sr\"]\n",
    "other_cols=[\"responseid\",\"yr_sch\",\"enroll\",\"aca_impa\",\"persist\"]\n",
    "load_cols = field_cols + degree_cols + gpa_cols + other_cols\n",
    "df = pd.read_csv(\"HMS_\"+str(year)+\"-\"+str(year+1)+\"_PUBLIC_instchars.csv\",usecols=load_cols)\n",
    "dfNew = df[field_cols + degree_cols + other_cols + gpa_cols].copy()\n",
    "dfNew[\"will_remove\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec176e-d077-4571-a55a-ab72f471fe7d",
   "metadata": {},
   "source": [
    "## Some basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2820c1-3af9-4269-ab95-fd88fad6efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5245cdd-d67a-40f4-a328-d09e870b3764",
   "metadata": {},
   "source": [
    "Ideally, we will change the type of columns using pandera package and verifying schema. Next time, maybe.\n",
    "\n",
    "Checking for duplicates (I didn't find any, all files clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccc7b0-6e76-4d5c-941d-9ede377f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_rows = df.duplicated(keep = False)\n",
    "print('Duplicate rows:', dup_rows.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314ba61-ac00-459b-90a2-c9b485841c6c",
   "metadata": {},
   "source": [
    "## Year of study (new *year* column)\n",
    "\n",
    "Usuall numerical value from 1 to 7 as per codebook, or Nan. In 2020, textual data were used so we have to treat this separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ecf109-3013-4ee4-859e-d84950eb2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yr_sch\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84460f-8f10-4141-9df3-fbb10f95ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 conversion\n",
    "if year != 2020:\n",
    "    dfNew[\"year\"] = df[\"yr_sch\"]\n",
    "else:\n",
    "    dfNew[\"year\"] = 1*(df[\"yr_sch\"] == '1st year') + 2*(df[\"yr_sch\"] == '2nd year') + 3*(df[\"yr_sch\"] == '3rd year') + 4*(df[\"yr_sch\"] == '4th year') + 5*(df[\"yr_sch\"] == '5th year') + 6*(df[\"yr_sch\"] == '6th year') + 7*(df[\"yr_sch\"] == '7th+ year')\n",
    "    dfNew[dfNew['year']==0] = np.nan\n",
    "    print(\"Updated value counts for 2020-2021:\")\n",
    "    print(dfNew[\"year\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04fa25-21ac-40da-b15d-1b48338d2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaNs: \" + str(np.sum(np.isnan(dfNew[\"year\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d876e-c14a-4edc-83db-f4c3dbd95155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d90a6f-31be-49b1-9508-4aa45b26225d",
   "metadata": {},
   "source": [
    "Let's filter out the NaNs. Some of them are non-degree students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a18f3-1acb-49a6-88b7-5e478da5b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"degree_nd\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b2390-1f4f-41e3-983b-0cd500b1b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2020:\n",
    "    dfNew.loc[df[\"degree_nd\"] == \"Non-degree student\",\"degree_nd\"] = 1.0\n",
    "    dfNew.loc[df[\"degree_nd\"] != \"Non-degree student\",\"degree_nd\"] = np.nan\n",
    "else:\n",
    "    dfNew[\"degree_nd\"] = df[\"degree_nd\"]\n",
    "dfNew[\"degree_nd\"] = dfNew[\"degree_nd\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a383816-360c-4511-9b36-85dd7b596d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"degree_nd\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cf50a-fae8-446d-a546-9696a798cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"degree_nd\"].value_counts(),np.sum(np.isnan(dfNew[\"degree_nd\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22fbc4-bdc3-4bb9-9e76-7eb8b319a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(dfNew[\"year\"]) & ~np.isnan(dfNew[\"degree_nd\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b696e81-d28e-405e-91ba-b0a4834f345f",
   "metadata": {},
   "source": [
    "So, let's remove degree students who did not specify their year of study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f2225-f5bd-4ea4-8d1f-d02ed851c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % np.sum(np.isnan(dfNew[\"year\"]) & np.isnan(dfNew[\"degree_nd\"])))\n",
    "dfNew[\"will_remove\"] |= ((np.isnan(dfNew[\"year\"])) & (np.isnan(dfNew[\"degree_nd\"])))\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ef570-facb-4250-9025-320155361da2",
   "metadata": {},
   "source": [
    "And check how many are flagged for removal, so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99248742-ed94-4b19-bbcb-776cceb2f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"will_remove\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f87c71-b997-4296-9154-98909716e285",
   "metadata": {},
   "source": [
    "## Enrollment (enroll)\n",
    "\n",
    "Non-degree students are not enrolled. Other NaNs to be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a58319-4f16-4b2f-861c-1782be6a945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"enroll\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612e3c7-21a9-4581-a2ff-7f76c3cedebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2020:\n",
    "    dfNew.loc[df[\"enroll\"] == \"Full-time student\",\"enroll\"] = 1.0\n",
    "    dfNew.loc[df[\"enroll\"] == \"Part-time student\",\"enroll\"] = 2.0\n",
    "    dfNew.loc[df[\"enroll\"] == \"Other (please specify)\",\"enroll\"] = 3.0\n",
    "    dfNew.loc[(dfNew[\"enroll\"] != 1.0) & (dfNew[\"enroll\"] != 2.0) & (dfNew[\"enroll\"] != 3.0),\"enroll\"] = np.nan\n",
    "else:\n",
    "    dfNew[\"enroll\"] = df[\"enroll\"]\n",
    "dfNew[\"enroll\"] = dfNew[\"enroll\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2916c27-a1d6-402d-be21-17d645de5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"enroll\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd678d3-62b4-44b7-abbc-2cae408c704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaNs: \" + str(np.sum(np.isnan(dfNew[\"enroll\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13defd5c-5a89-4f60-a0c6-46531ebfa9c1",
   "metadata": {},
   "source": [
    "Non-degree students are not enrolled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf178e7-b14a-44d5-889c-0ec80971d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(dfNew[\"enroll\"]) & np.isnan(dfNew[\"degree_nd\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87628e4b-de65-4071-8eb8-448d7a00144d",
   "metadata": {},
   "source": [
    "So, filter other out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aec26f-7b58-42d7-8eee-6c9bf5981520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % np.sum((np.isnan(dfNew[\"enroll\"]) & ~np.isnan(dfNew[\"degree_nd\"]))))\n",
    "dfNew[\"will_remove\"] |= (np.isnan(dfNew[\"enroll\"]) & ~np.isnan(dfNew[\"degree_nd\"]))\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32234c09-51ee-4985-9eba-b6fd7aa79931",
   "metadata": {},
   "source": [
    "## GPA, gpa_sr\n",
    "\n",
    "Same routine here, except since 2020 other convention is used. I convert old to the new one since latter is less specific. The final scheme is as follows:\n",
    "1. Mostly A's; 2. Mostly B's; 3. Mostly C's; 4. Mostly D's; 5. Mostly F's; 6. None of these; 7. No grade or don't know\n",
    "   \n",
    "The format is 1.0 (True) and NaN (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83391fc-b681-402e-8cd9-f4f6440e0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year>=2020:\n",
    "    df[gpa_cols[0]].value_counts(),df[gpa_cols[0]].unique()\n",
    "else:\n",
    "    dfNew[\"gpa_sr\"] = df[\"gpa_sr\"]\n",
    "    print(df[\"gpa_sr\"].value_counts(),df[\"gpa_sr\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1a871-fbff-4824-bdf1-5e15388901e7",
   "metadata": {},
   "source": [
    "If year is 2020, convert textual information into 1 (selected) or NaN (not selected), as in other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2ed1a-4099-4491-9240-bd0f8469de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2020:\n",
    "    for gr in gpa_cols:\n",
    "        gr_name=list(df[gr].value_counts().to_dict().keys())[0]\n",
    "        # then make it 1 in dfNew, and NaN otherwise\n",
    "        dfNew.loc[df[gr] == gr_name,gr] = 1.0\n",
    "        dfNew.loc[dfNew[gr] != 1.0,gr] = np.nan\n",
    "        dfNew[gr] = dfNew[gr].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2586512-e200-473f-aa37-bf162d2d681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year >= 2020:\n",
    "    for gr in gpa_cols:\n",
    "        print(dfNew[gr].value_counts(),np.sum(np.isnan(dfNew[gr])))\n",
    "else:\n",
    "    print(dfNew[\"gpa_sr\"].value_counts(),np.sum(np.isnan(dfNew[\"gpa_sr\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0c0d4-f99e-4f58-9428-e420e682a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year>=2020:\n",
    "    j=1\n",
    "    dfNew[\"gpa_sr\"] = 0\n",
    "    dfNew[\"gpa_check\"] = 0\n",
    "    for gr in gpa_cols:\n",
    "        dfNew[\"gpa_sr\"] += j*(~np.isnan(dfNew[gr]))\n",
    "        dfNew[\"gpa_check\"] += 1*(~np.isnan(dfNew[gr]))\n",
    "        j += 1\n",
    "    # if more than two GPAs is selected or none at all, remove it.\n",
    "    dfNew.loc[dfNew[\"gpa_check\"]>2,\"gpa_sr\"] = np.nan\n",
    "    dfNew.loc[dfNew[\"gpa_check\"]==0,\"gpa_sr\"] = np.nan\n",
    "else:\n",
    "    dfNew.loc[(df[\"gpa_sr\"] > -1) & (df[\"gpa_sr\"] < 2.5),\"gpa_sr\"] = 1\n",
    "    dfNew.loc[(df[\"gpa_sr\"] > 2.5) & (df[\"gpa_sr\"] < 5.5),\"gpa_sr\"] = 2\n",
    "    dfNew.loc[(df[\"gpa_sr\"] > 5.5) & (df[\"gpa_sr\"] < 8.5),\"gpa_sr\"] = 3\n",
    "    dfNew.loc[(df[\"gpa_sr\"] > 8.5) & (df[\"gpa_sr\"] < 9.5),\"gpa_sr\"] = 4\n",
    "    dfNew.loc[(df[\"gpa_sr\"] > 9.5) & (df[\"gpa_sr\"] < 10.5),\"gpa_sr\"] = 7\n",
    "    dfNew[\"gpa_check\"] = 1\n",
    "    dfNew.loc[np.isnan(df[\"gpa_sr\"]),\"gpa_sr\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292f032-4d52-4314-9d1a-f200e34b5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"gpa_sr\"].value_counts(),np.sum(np.isnan(dfNew[\"gpa_sr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f009e-258d-4315-92c3-a676b89c5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"gpa_check\"].value_counts(),np.sum(np.isnan(dfNew[\"gpa_check\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40852770-eba1-497c-af40-fee2ac590803",
   "metadata": {},
   "source": [
    "I think I know what's going on. Some people marked A's and C's, or B's and D's. What do we do about it? I'm thinking we can compute some kinda average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97707bb7-5fd7-4a05-8e36-f339d949e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.loc[dfNew[\"gpa_check\"]==2,gpa_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc3253-f57a-4f60-bb28-1e5994c9da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year>=2020:\n",
    "    j=1\n",
    "    # reset the GPA of those selecting two checkboxes, then find the average\n",
    "    dfNew.loc[dfNew[\"gpa_check\"]==2,\"gpa_sr\"] = 0\n",
    "    for gr in gpa_cols:\n",
    "        # no combos with \"none of these\" and \"no grade\"\n",
    "        if j>5:\n",
    "            continue\n",
    "        dfNew.loc[dfNew[\"gpa_check\"]==2,\"gpa_sr\"] += j*(~np.isnan(dfNew[gr]))*0.5\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164c817-c0d7-4008-8b35-b36fc876bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNew.loc[(dfNew[\"gpa_check\"]<=2) & (dfNew[\"gpa_check\"]>0),\"gpa_sr\"].value_counts()\n",
    "dfNew[\"gpa_sr\"].value_counts(),np.sum(np.isnan(dfNew[\"gpa_sr\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbdbbd-206f-495f-bee0-124cfd30eaa0",
   "metadata": {},
   "source": [
    "**Finally**, filter out NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d5a31-5cc7-43f1-8a39-d05b49b656c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % np.sum(np.isnan(dfNew[\"gpa_sr\"])))\n",
    "dfNew[\"will_remove\"] |= np.isnan(dfNew[\"gpa_sr\"])\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64e064-5eaf-405b-ba80-3eb1b6ae9e50",
   "metadata": {},
   "source": [
    "## Academic impact, aca_impa\n",
    "\n",
    "For 2020, textual format was used. Since removing NaNs gets rid of too many items, I put the value corresponding to the situation where is no academic impact on their studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7799b2d-375d-492a-a06d-4d329e885298",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year != 2020:\n",
    "    print(df[\"aca_impa\"].value_counts(),df[\"aca_impa\"].unique(),np.sum(np.isnan(df[\"aca_impa\"])))\n",
    "else:\n",
    "    print(df[\"aca_impa\"].value_counts(),df[\"aca_impa\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69fbc7-a4d0-4b1a-8cc3-74a8c8c7c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2020:\n",
    "    dfNew.loc[df[\"aca_impa\"] == \"1-2 days\",\"aca_impa\"] = 2.0\n",
    "    dfNew.loc[df[\"aca_impa\"] == \"3-5 days\",\"aca_impa\"] = 3.0\n",
    "    dfNew.loc[df[\"aca_impa\"] == \"6 or more days\",\"aca_impa\"] = 4.0\n",
    "    dfNew.loc[(dfNew[\"aca_impa\"] != 2.0) & (dfNew[\"aca_impa\"] != 3.0) & (dfNew[\"aca_impa\"] != 4.0),\"aca_impa\"] = 1.0\n",
    "else:\n",
    "    dfNew[\"aca_impa\"] = df[\"aca_impa\"]\n",
    "dfNew[\"aca_impa\"] = dfNew[\"aca_impa\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e07245-9ab3-41a8-9cf1-b3a6882b761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % np.sum(np.isnan(dfNew[\"aca_impa\"])))\n",
    "dfNew[\"will_remove\"] |= np.isnan(dfNew[\"aca_impa\"])\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22974df-34f4-4073-a9e2-accba995c132",
   "metadata": {},
   "source": [
    "## Persistence (persist)\n",
    "\n",
    "1..6 (Strongly agree..Strongly disagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a372a-c114-4bcd-b7d8-386dd531f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"persist\"].value_counts(),df[\"persist\"].unique(),np.sum(np.isnan(df[\"persist\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf78b9-0f7e-4769-9867-8fdc09b5c7bb",
   "metadata": {},
   "source": [
    "Fortunately, in 2020 all is numerical. Filter out those that are NaNs or aren't between 1 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04cb3f-8000-4de2-8271-4e14269d2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"persist\"] = df[\"persist\"]\n",
    "if year == 2020:\n",
    "    dfNew.loc[(df[\"persist\"] < 1) | (df[\"persist\"] > 6),\"persist\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbaa12-8959-4072-a2d7-a188c8353c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % np.sum(np.isnan(dfNew[\"persist\"])))\n",
    "dfNew[\"will_remove\"] |= np.isnan(dfNew[\"persist\"])\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2bb74-4c70-4a66-8ef0-4bd3735905b3",
   "metadata": {},
   "source": [
    "## Degree (new column *degree*)\n",
    "\n",
    "Note: 2020 degree_nd has been processed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72207851-a134-4c51-b376-e7ab66cb401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year != 2020:\n",
    "    print(df[\"degree_other\"].value_counts(),df[\"degree_other\"].unique(),np.sum(np.isnan(df[\"degree_other\"])))\n",
    "else:\n",
    "    print(df[\"degree_other\"].value_counts(),df[\"degree_other\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55324e74-6317-42cf-82e3-5b0ff49d4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2020:\n",
    "    dfNew.loc[df[\"degree_ass\"] == \"Associate's\",\"degree_ass\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_ass\"] != 1.0,\"degree_ass\"] = np.nan\n",
    "\n",
    "    dfNew.loc[df[\"degree_bach\"] == \"Bachelor's\",\"degree_bach\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_bach\"] != 1.0,\"degree_bach\"] = np.nan\n",
    "\n",
    "    dfNew.loc[df[\"degree_ma\"] == \"Master's\",\"degree_ma\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_ma\"] != 1.0,\"degree_ma\"] = np.nan\n",
    "\n",
    "    dfNew.loc[df[\"degree_jd\"] == \"jd\",\"degree_jd\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_jd\"] != 1.0,\"degree_jd\"] = np.nan\n",
    "\n",
    "    dfNew.loc[df[\"degree_phd\"] == \"PhD (or equivalent doctoral program)\",\"degree_phd\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_phd\"] != 1.0,\"degree_phd\"] = np.nan\n",
    "\n",
    "    dfNew.loc[df[\"degree_other\"] == \"Other (please specify)\",\"degree_other\"] = 1.0\n",
    "    dfNew.loc[dfNew[\"degree_other\"] != 1.0,\"degree_other\"] = np.nan\n",
    "else:\n",
    "    dfNew[\"degree_ass\"] = df[\"degree_ass\"]\n",
    "    dfNew[\"degree_bach\"] = df[\"degree_bach\"]\n",
    "    dfNew[\"degree_ma\"] = df[\"degree_ma\"]\n",
    "    dfNew[\"degree_jd\"] = df[\"degree_jd\"]\n",
    "    dfNew[\"degree_phd\"] = df[\"degree_phd\"]\n",
    "    dfNew[\"degree_other\"] = df[\"degree_other\"]\n",
    "dfNew[\"degree_ass\"] = dfNew[\"degree_ass\"].astype(np.float64)\n",
    "dfNew[\"degree_bach\"] = dfNew[\"degree_bach\"].astype(np.float64)\n",
    "dfNew[\"degree_ma\"] = dfNew[\"degree_ma\"].astype(np.float64)\n",
    "dfNew[\"degree_jd\"] = dfNew[\"degree_jd\"].astype(np.float64)\n",
    "dfNew[\"degree_phd\"] = dfNew[\"degree_phd\"].astype(np.float64)\n",
    "dfNew[\"degree_other\"] = dfNew[\"degree_other\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d5059-cd47-4965-b056-0672633e4f2f",
   "metadata": {},
   "source": [
    "Create a new column \"degree\" and perform a few sanity checks on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65851bf7-2a56-4bc4-bd24-9a076f38a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"degree\"] = 1*(~np.isnan(dfNew[\"degree_ass\"]))+2*(~np.isnan(dfNew[\"degree_bach\"]))+3*(~np.isnan(dfNew[\"degree_ma\"]))+4*(~np.isnan(dfNew[\"degree_jd\"]))+5*(~np.isnan(dfNew[\"degree_phd\"]))+6*(~np.isnan(dfNew[\"degree_other\"]))+7*(~np.isnan(dfNew[\"degree_nd\"]))\n",
    "dfNew[\"degreeCheck\"] = 1*(~np.isnan(dfNew[\"degree_ass\"]))+1*(~np.isnan(dfNew[\"degree_bach\"]))+1*(~np.isnan(dfNew[\"degree_ma\"]))+1*(~np.isnan(dfNew[\"degree_jd\"]))+1*(~np.isnan(dfNew[\"degree_phd\"]))+1*(~np.isnan(dfNew[\"degree_other\"]))+1*(~np.isnan(dfNew[\"degree_nd\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979224e-2eb1-4aa5-97dc-7a88a29fa4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"degreeCheck\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70440d4-1362-4b8d-b03c-fcb9bf8caa96",
   "metadata": {},
   "source": [
    "Filter out those doing zero degrees and more than two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9fa8f-cb45-4a37-9d94-084a8b9604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % (np.sum((dfNew[\"degreeCheck\"]>2) | (dfNew[\"degreeCheck\"] < 1))))\n",
    "dfNew[\"will_remove\"] |= (dfNew[\"degreeCheck\"]>2) | (dfNew[\"degreeCheck\"] < 1)\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31225280-c8c3-4fbb-9395-41de021dfa97",
   "metadata": {},
   "source": [
    "## Field (new column *field*)\n",
    "\n",
    "First off, we have to sort out 2020 mess. Since we have 20 different columns, I will have to automate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e997631-19f2-46d0-82cf-bb07068c4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year != 2020:\n",
    "    print(df[\"field_hum\"].value_counts(),df[\"field_hum\"].unique(),np.sum(np.isnan(df[\"field_hum\"])))\n",
    "else:\n",
    "    print(df[\"field_hum\"].value_counts(),df[\"field_hum\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369067fc-2774-49cd-8427-e0f86f15a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[\"field_hum\"].value_counts().to_dict().keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75459f-38ab-4dea-9a60-a6d4fc410fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in field_cols:\n",
    "    if year == 2020:\n",
    "        # select most populous entry\n",
    "        field_name=list(df[field].value_counts().to_dict().keys())[0]\n",
    "        # then make it 1 in dfNew, and NaN otherwise\n",
    "        dfNew.loc[df[field] == field_name,field] = 1.0\n",
    "        dfNew.loc[dfNew[field] != 1.0,field] = np.nan\n",
    "    else:\n",
    "        dfNew[field] = df[field]\n",
    "    dfNew[field] = dfNew[field].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b919a77-0a69-4327-8a7b-54788de1b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"field_nat\"].value_counts(),dfNew[\"field_nat\"].unique(),np.sum(np.isnan(dfNew[\"field_nat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b32c9-0443-4522-9291-8952f762c471",
   "metadata": {},
   "source": [
    "Now we are finally ready to create a field column. This is a preliminary version, hot encoding will be required later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeabeb1-f634-490b-92a1-e0676b10715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"field\"]=1*(~np.isnan(dfNew[\"field_hum\"]))+2*(~np.isnan(dfNew[\"field_nat\"]))+3*(~np.isnan(dfNew[\"field_soc\"]))+4*(~np.isnan(dfNew[\"field_arc\"]))+5*(~np.isnan(dfNew[\"field_art\"]))+6*(~np.isnan(dfNew[\"field_bus\"]))+7*(~np.isnan(dfNew[\"field_den\"]))+8*(~np.isnan(dfNew[\"field_ed\"]))+9*(~np.isnan(dfNew[\"field_eng\"]))+10*(~np.isnan(dfNew[\"field_law\"]))+11*(~np.isnan(dfNew[\"field_med\"]))+12*(~np.isnan(dfNew[\"field_mus\"]))+13*(~np.isnan(dfNew[\"field_nur\"]))+14*(~np.isnan(dfNew[\"field_pharm\"]))+15*(~np.isnan(dfNew[\"field_prep\"]))+16*(~np.isnan(dfNew[\"field_ph\"]))+17*(~np.isnan(dfNew[\"field_pp\"]))+18*(~np.isnan(dfNew[\"field_sw\"]))+19*(~np.isnan(dfNew[\"field_und\"]))+20*(~np.isnan(dfNew[\"field_other\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6910cbc-a2d4-475e-a697-2e617a5d2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"field\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea0127-789f-407c-a8f0-0b10843e928a",
   "metadata": {},
   "source": [
    "Some a bogus, of course. Let's filter out those doing more than 3 fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e346adb-55cc-4e32-ba7e-6f249ecdd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "dfNew[\"fieldCheck\"]=0\n",
    "for field in field_cols:\n",
    "    dfNew[\"fieldCheck\"] += 1*(~np.isnan(dfNew[field]))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d7562-67f2-4a22-ac5a-fdfd89f76575",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew[\"fieldCheck\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a6a20-bc3f-4434-bc1a-6cbbd2e147e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dfNew[\"fieldCheck\"] > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cabd5f-69f6-489a-8106-cc59a0f6f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Flagging %d entries for removal\" % (np.sum(dfNew[\"fieldCheck\"]>3)))\n",
    "dfNew[\"will_remove\"] |= dfNew[\"fieldCheck\"]>3\n",
    "print(\"Total to be removed: %d\\n\" % np.sum(dfNew[\"will_remove\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c268a-7ab0-41a7-8a47-e4517e6022f4",
   "metadata": {},
   "source": [
    "## Saving data into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d49ce1-2534-4b89-93aa-cd260ee8b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Warning: Total data to be removed: %.2f percent \\n\" % (np.sum(dfNew[\"will_remove\"])/len(dfNew)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8707d8-055f-4e9b-8698-0cc80cd495e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6aabf-6287-4ea2-b430-8b40b14fe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols=['responseid', 'will_remove','year', 'enroll', 'gpa_sr', 'aca_impa', 'persist', 'degree',  'field'   ] + degree_cols + field_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a7395-f047-4638-a1fd-40b10e0b6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.to_csv(str(year) + '-' + str(year+1) + '_Alexandr.csv',columns=output_cols,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
